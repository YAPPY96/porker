import rlcard
from rlcard.agents import DQNAgent
import torch
import os
import glob
from blackjack_utils import get_score, print_hand, decode_card, get_action_name

# ---------------------------------------------------------
# è¨­å®š
# ---------------------------------------------------------
SAVE_DIR = 'experiments/blackjack_custom_reward' # ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´æ‰€
LOG_DIR = 'logs'                                 # ãƒ­ã‚°ä¿å­˜å…ˆ
GAMES_PER_MODEL = 5                              # è¨˜éŒ²ã™ã‚‹ã‚²ãƒ¼ãƒ æ•°

# ãƒ­ã‚°ä¿å­˜ç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
if not os.path.exists(LOG_DIR):
    os.makedirs(LOG_DIR)

# ---------------------------------------------------------
# 1. æº–å‚™
# ---------------------------------------------------------
env = rlcard.make('blackjack')
agent = DQNAgent(
    num_actions=env.num_actions,
    state_shape=env.state_shape[0],
    mlp_layers=[128, 128],
    device=torch.device("cpu")
)
env.set_agents([agent])

# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
model_files = glob.glob(os.path.join(SAVE_DIR, 'model_*.pth'))
model_files.sort()

if not model_files:
    print(f"Error: No models found in {SAVE_DIR}")
    exit()

print(f"Found {len(model_files)} models. Saving logs to '{LOG_DIR}/'...\n")

# ---------------------------------------------------------
# 2. ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ãƒ­ã‚°ä¿å­˜ã—ãªãŒã‚‰å®Ÿè¡Œ
# ---------------------------------------------------------
for model_path in model_files:
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ€§æ ¼åã‚’å–å¾—
    personality = os.path.basename(model_path).replace('model_', '').replace('.pth', '')
    
    # ä¿å­˜ã™ã‚‹ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    log_file_path = os.path.join(LOG_DIR, f"log_{personality}.txt")
    
    print(f"Processing {personality}... (Saving to {log_file_path})")

    # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
    try:
        agent.q_estimator.qnet.load_state_dict(torch.load(model_path))
    except Exception as e:
        print(f"  Load Error: {e}")
        continue

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦æ›¸ãè¾¼ã‚€æº–å‚™
    # encoding='utf-8' ã«ã™ã‚‹ã“ã¨ã§çµµæ–‡å­—ï¼ˆğŸ†ãªã©ï¼‰ã®æ–‡å­—åŒ–ã‘ã‚’é˜²ãã¾ã™
    with open(log_file_path, 'w', encoding='utf-8') as f:
        
        # ç”»é¢å‡ºåŠ›ã¨ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚’åŒæ™‚ã«è¡Œã†ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
        def log(text):
            # print(text) # ç”»é¢ã«ã‚‚å‡ºã—ãŸã„å ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã™
            f.write(text + "\n")

        # ãƒ˜ãƒƒãƒ€ãƒ¼æ›¸ãè¾¼ã¿
        log("="*60)
        log(f" ã€ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ€§æ ¼: {personality.upper()} ã€‘")
        log("="*60)

        # ã‚²ãƒ¼ãƒ å®Ÿè¡Œãƒ«ãƒ¼ãƒ—
        for i in range(GAMES_PER_MODEL):
            log(f"\n--- Game {i+1} ---")
            state, player_id = env.reset()
            
            step_count = 1
            while not env.is_over():
                raw_obs = state['raw_obs']
                p_hand = raw_obs['player0 hand']
                d_hand = raw_obs['dealer hand']
                
                p_score = get_score(p_hand)
                d_up_card = decode_card(d_hand[0]) if d_hand else "?"

                # AIã®æ±ºæ–­
                action, _ = agent.eval_step(state)
                act_str = get_action_name(action)

                # ãƒ­ã‚°è¨˜éŒ²
                log(f"  Step {step_count}:")
                log(f"    Player: {print_hand(p_hand)} (Score: {p_score})")
                log(f"    Dealer: {d_up_card} (Hidden)")
                log(f"    -> Action: {act_str}")

                state, next_player_id = env.step(action, player_id)
                step_count += 1

            # --- æœ€çµ‚çµæœ ---
            final_obs = state['raw_obs']
            p_final = final_obs['player0 hand']
            d_final = final_obs['dealer hand']
            
            p_final_score = get_score(p_final)
            d_final_score = get_score(d_final)
            
            payoffs = env.get_payoffs()
            score = payoffs[player_id]

            if score > 0:
                result = "WIN ğŸ†"
            elif score < 0:
                result = "LOSE ğŸ’€"
            else:
                result = "DRAW ğŸ¤"

            log(f"  [Result] {result}")
            log(f"    Player Final: {print_hand(p_final)} (Score: {p_final_score})")
            log(f"    Dealer Final: {print_hand(d_final)} (Score: {d_final_score})")

print("\nAll logs saved successfully! Check the 'logs' folder.")